/**
 * INTENT ANALYZER - Sistema de An√°lise de Inten√ß√£o
 *
 * Classifica a inten√ß√£o da mensagem do usu√°rio ANTES do processamento principal,
 * permitindo que Sara escolha a melhor estrat√©gia de resposta.
 *
 * Usa modelo r√°pido e econ√¥mico para an√°lise preliminar.
 */

import { HumanMessage, SystemMessage } from "@langchain/core/messages";

/**
 * Tipos de inten√ß√£o suportados
 */
export const INTENT_TYPES = {
  PERGUNTA_DIRETA_NEGOCIO: 'pergunta_direta_negocio',
  PEDIDO_ORCAMENTO: 'pedido_orcamento',
  EXPRESSA_INTERESSE: 'expressa_interesse',
  OBJECAO: 'objecao',
  FORNECE_INFO: 'fornece_info',
  SAUDACAO: 'saudacao',
  DUVIDA_TECNICA: 'duvida_tecnica',
  AGRADECIMENTO: 'agradecimento',
  DESPEDIDA: 'despedida'
};

/**
 * Metodologias recomendadas por inten√ß√£o
 */
export const INTENT_TO_METHODOLOGY = {
  [INTENT_TYPES.PERGUNTA_DIRETA_NEGOCIO]: 'direta',
  [INTENT_TYPES.PEDIDO_ORCAMENTO]: 'bant',
  [INTENT_TYPES.EXPRESSA_INTERESSE]: 'spin',
  [INTENT_TYPES.OBJECAO]: 'value_first',
  [INTENT_TYPES.FORNECE_INFO]: 'spin',
  [INTENT_TYPES.SAUDACAO]: 'direta',
  [INTENT_TYPES.DUVIDA_TECNICA]: 'direta',
  [INTENT_TYPES.AGRADECIMENTO]: 'direta',
  [INTENT_TYPES.DESPEDIDA]: 'direta'
};

/**
 * Analisador de inten√ß√£o baseado em regras (fallback r√°pido)
 */
export class RuleBasedIntentAnalyzer {
  analyze(userMessage, context = {}) {
    const lowerMsg = userMessage.toLowerCase().trim();

    // SAUDA√á√ÉO
    if (this.isSaudacao(lowerMsg)) {
      return {
        intent: INTENT_TYPES.SAUDACAO,
        methodology: 'direta',
        confidence: 90,
        reason: 'Detectado cumprimento inicial'
      };
    }

    // DESPEDIDA
    if (this.isDespedida(lowerMsg)) {
      return {
        intent: INTENT_TYPES.DESPEDIDA,
        methodology: 'direta',
        confidence: 95,
        reason: 'Detectada despedida'
      };
    }

    // AGRADECIMENTO
    if (this.isAgradecimento(lowerMsg)) {
      return {
        intent: INTENT_TYPES.AGRADECIMENTO,
        methodology: 'direta',
        confidence: 90,
        reason: 'Detectado agradecimento'
      };
    }

    // PEDIDO DE OR√áAMENTO
    if (this.isPedidoOrcamento(lowerMsg)) {
      return {
        intent: INTENT_TYPES.PEDIDO_ORCAMENTO,
        methodology: 'bant',
        confidence: 85,
        reason: 'Detectada pergunta sobre pre√ßo/prazo'
      };
    }

    // OBJE√á√ÉO
    if (this.isObjecao(lowerMsg)) {
      return {
        intent: INTENT_TYPES.OBJECAO,
        methodology: 'value_first',
        confidence: 80,
        reason: 'Detectada obje√ß√£o ou preocupa√ß√£o'
      };
    }

    // D√öVIDA T√âCNICA
    if (this.isDuvidaTecnica(lowerMsg)) {
      return {
        intent: INTENT_TYPES.DUVIDA_TECNICA,
        methodology: 'direta',
        confidence: 75,
        reason: 'Detectada pergunta t√©cnica'
      };
    }

    // PERGUNTA DIRETA SOBRE NEG√ìCIO
    if (this.isPerguntaDiretaNegocio(lowerMsg)) {
      return {
        intent: INTENT_TYPES.PERGUNTA_DIRETA_NEGOCIO,
        methodology: 'direta',
        confidence: 80,
        reason: 'Detectada pergunta sobre servi√ßos'
      };
    }

    // EXPRESSA INTERESSE
    if (this.isExpressaInteresse(lowerMsg)) {
      return {
        intent: INTENT_TYPES.EXPRESSA_INTERESSE,
        methodology: 'spin',
        confidence: 70,
        reason: 'Detectado interesse em servi√ßo'
      };
    }

    // FORNECE INFO (contexto de conversa ativa)
    if (context.mensagens_trocadas > 0) {
      return {
        intent: INTENT_TYPES.FORNECE_INFO,
        methodology: 'spin',
        confidence: 60,
        reason: 'Cliente respondendo em conversa ativa'
      };
    }

    // DEFAULT
    return {
      intent: INTENT_TYPES.EXPRESSA_INTERESSE,
      methodology: 'spin',
      confidence: 50,
      reason: 'Inten√ß√£o n√£o clara, usando padr√£o'
    };
  }

  // M√©todos de detec√ß√£o

  isSaudacao(msg) {
    const saudacoes = ['oi', 'ol√°', 'ola', 'bom dia', 'boa tarde', 'boa noite', 'e a√≠', 'eai', 'hey', 'hello'];
    return saudacoes.some(s => msg.startsWith(s) || msg === s);
  }

  isDespedida(msg) {
    const despedidas = ['tchau', 'at√© logo', 'at√© mais', 'obrigado, √© s√≥', 'valeu, tchau', 'flw'];
    return despedidas.some(d => msg.includes(d));
  }

  isAgradecimento(msg) {
    const agradecimentos = ['obrigado', 'obrigada', 'valeu', 'agrade√ßo'];
    return agradecimentos.some(a => msg.includes(a)) && !msg.includes('?');
  }

  isPedidoOrcamento(msg) {
    const keywords = ['quanto cust', 'qual o pre√ßo', 'qual o valor', 'quanto √©', 'quanto sai',
                      'quanto fic', 'pre√ßo', 'valor', 'or√ßamento', 'prazo', 'quanto tempo'];
    return keywords.some(k => msg.includes(k));
  }

  isObjecao(msg) {
    const objecoes = ['caro', 'cara', 'muito dinheiro', 'n√£o tenho', 'preciso pensar',
                      'vou pensar', 'vou ver', 'vi mais barato', 'encontrei por'];
    return objecoes.some(o => msg.includes(o));
  }

  isDuvidaTecnica(msg) {
    const tecnicos = ['como funciona', 'integra', 'compat√≠vel', 'responsiv', 'mobile',
                      'whatsapp', 'instagram', 'facebook', 'seo', 'google', 'ssl', 'segur'];
    return tecnicos.some(t => msg.includes(t));
  }

  isPerguntaDiretaNegocio(msg) {
    const perguntas = ['voc√™s faz', 'voc√™s vend', 'voc√™s trabalh', 'voc√™s tem',
                       'voc√™ faz', 'tem como fazer', 'fazem'];
    return perguntas.some(p => msg.includes(p));
  }

  isExpressaInteresse(msg) {
    const interesse = ['quero', 'preciso', 'gostaria', 'queria', 'tenho interesse',
                       'me interessa', 'procuro'];
    return interesse.some(i => msg.includes(i));
  }
}

/**
 * Analisador de inten√ß√£o baseado em LLM (mais preciso)
 */
export class LLMIntentAnalyzer {
  constructor(apiManager) {
    this.apiManager = apiManager;
    this.ruleBasedFallback = new RuleBasedIntentAnalyzer();
  }

  /**
   * Analisa inten√ß√£o usando LLM r√°pido
   */
  async analyze(userMessage, context = {}) {
    try {
      // Tenta com LLM
      const model = this.apiManager.getFastModel();

      const systemPrompt = `Voc√™ √© um classificador de inten√ß√£o para chatbot de vendas.

TIPOS DE INTEN√á√ÉO:
1. pergunta_direta_negocio - Cliente pergunta se fazemos/vendemos algo espec√≠fico
2. pedido_orcamento - Cliente quer saber pre√ßo, prazo, custo
3. expressa_interesse - Cliente diz que quer/precisa de algo
4. objecao - Cliente expressa preocupa√ß√£o (pre√ßo alto, precisa pensar, etc)
5. fornece_info - Cliente est√° respondendo pergunta nossa
6. saudacao - Cumprimento inicial (oi, bom dia, etc)
7. duvida_tecnica - Pergunta sobre funcionamento t√©cnico
8. agradecimento - Cliente agradece
9. despedida - Cliente se despede

CONTEXTO:
- Mensagens trocadas: ${context.mensagens_trocadas || 0}
- Lead score atual: ${context.score || 0}/4

MENSAGEM DO CLIENTE:
"${userMessage}"

Responda APENAS com JSON v√°lido:
{
  "intent": "tipo_da_intencao",
  "methodology": "direta|spin|bant|value_first",
  "confidence": 0-100,
  "reason": "explica√ß√£o breve"
}`;

      const messages = [
        new SystemMessage(systemPrompt),
        new HumanMessage("Classifique a inten√ß√£o")
      ];

      const response = await model.invoke(messages);
      const result = this.parseJSON(response.content);

      // Valida resultado
      if (result.intent && result.methodology && result.confidence) {
        return result;
      }

      throw new Error('Resposta LLM inv√°lida');

    } catch (error) {
      console.warn('‚ö†Ô∏è Falha na an√°lise LLM, usando regras:', error.message);
      return this.ruleBasedFallback.analyze(userMessage, context);
    }
  }

  parseJSON(content) {
    try {
      const cleaned = content
        .replace(/```json\n?/g, '')
        .replace(/```\n?/g, '')
        .trim();
      return JSON.parse(cleaned);
    } catch (e) {
      throw new Error('Falha ao parsear JSON');
    }
  }
}

/**
 * Analisador de inten√ß√£o h√≠brido (combina regras + LLM)
 */
export class HybridIntentAnalyzer {
  constructor(apiManager) {
    this.ruleBased = new RuleBasedIntentAnalyzer();
    this.llmBased = new LLMIntentAnalyzer(apiManager);
  }

  /**
   * Analisa usando regras primeiro, LLM se necess√°rio
   */
  async analyze(userMessage, context = {}) {
    // 1. Tenta com regras (instant√¢neo, gr√°tis)
    const ruleResult = this.ruleBased.analyze(userMessage, context);

    // 2. Se confian√ßa alta, usa resultado das regras
    if (ruleResult.confidence >= 80) {
      console.log(`üéØ Inten√ß√£o detectada (regras): ${ruleResult.intent} (${ruleResult.confidence}%)`);
      return ruleResult;
    }

    // 3. Se confian√ßa baixa, usa LLM para refinar
    console.log(`ü§î Confian√ßa baixa (${ruleResult.confidence}%), consultando LLM...`);
    try {
      const llmResult = await this.llmBased.analyze(userMessage, context);
      console.log(`üéØ Inten√ß√£o refinada (LLM): ${llmResult.intent} (${llmResult.confidence}%)`);
      return llmResult;
    } catch (error) {
      console.warn('‚ö†Ô∏è LLM falhou, usando resultado das regras');
      return ruleResult;
    }
  }
}

/**
 * Factory function para criar analisador
 */
export function createIntentAnalyzer(apiManager, mode = 'hybrid') {
  switch (mode) {
    case 'rules':
      return new RuleBasedIntentAnalyzer();
    case 'llm':
      return new LLMIntentAnalyzer(apiManager);
    case 'hybrid':
    default:
      return new HybridIntentAnalyzer(apiManager);
  }
}
